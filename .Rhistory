f.ar1 <- forecast(fit.ar1,h=h)
f.ar1
# Plot the resulting forecast and prediction intervals
plot(f.ar1)
# Add the true test values to the plot
lines(y.test,col="red")
# MA(1) Model
'************'
fit.ma1 <- Arima(y,c(0,0,1))
fit.ma1
# Forecasting
f.ma1 <- forecast(fit.ma1,h=h)
f.ma1
# Plot the resulting forecast and prediction intervals
plot(f.ma1)
# Add the true test values to the plot
lines(y.test,col="red")
# auto.arima() -- Automatically select ARIMA Model
'**************************************************'
fit.arima <- auto.arima(y)
fit.arima
# Forecasting
f.arima <- forecast(fit.arima, h=h)
f.arima
# Check the following two commands--- needs correction
plot(f.arima)
lines(y.test,col="red")
# Trigonometric Exponential Smoothing (TBATS) Method
'***************************************************'
fit.tbats <- tbats(y)
f.tbats <- forecast(fit.tbats,h=h)
plot(f.tbats)
lines(y.test,col="red")
# Theta using 'tsutils' package
'******************************'
fit.theta <- theta(y)
fit.theta
plot(fit.theta)
f.theta <- forecast.theta(fit.theta,h=h)
plot(f.theta)
lines(y.test,col="red")
# Theta Models using forecTheta package
'**************************************'
library(forecTheta)
fit.stheta <- stheta(y, h=h, s=NULL)
fit.stheta
plot(fit.stheta)
lines(y.test,col="red")
# Optimized Theta model (otm)
'****************************'
fit.otm <- otm(y, level=NULL, h=h, opt.method="Nelder-Mead")
fit.otm
plot(fit.otm)
lines(y.test,col="red")
# Measures of Forecast Accuracy
'------------------------------'
accuracy(f.arima) # Gives only in-sample accuracy
accuracy(f.arima,y.test) # Gives in-sample & out-of-sample accuracy
accuracy(f.arima$mean,y.test) # Gives out-of-sample accuracy
# 1. In-Sample Forecast Accuracy
'*******************************'
MEAN <- accuracy(f.mean)
NAIVE <- accuracy(f.naive)
SNAIVE <- accuracy(f.snaive)
DRIFT <- accuracy(f.drift)
SES <- accuracy(f.ses)
HOLTLINEAR <- accuracy(f.holtlinear)
HOLTWINTER_M <- accuracy(f.hw)
AUTO_ETS <- accuracy(f.ets)
AUTO_ARIMA <- accuracy(f.arima)
TBATS <- accuracy(f.tbats)
THETA <- accuracy(f.theta)
f.all <-rbind(MEAN, NAIVE, SNAIVE, DRIFT, SES, HOLTLINEAR, HOLTWINTER_M,
AUTO_ETS, AUTO_ARIMA, TBATS, THETA)
rownames(f.all) <- c("MEAN","NAIVE","SNAIVE","DRIFT","SES","HOLT LINEAR",
"Multiplicative Holt-Winters","Auto ETS Model",
"Auto ARIMA Model", "TBATS", "Theta Method")
f.all
# 2. Out-of-Sample Forecast Accuracy
'***********************************'
MEAN <- accuracy(f.mean$mean,y.test)
NAIVE <- accuracy(f.naive$mean,y.test)
SNAIVE <- accuracy(f.snaive$mean,y.test)
DRIFT <- accuracy(f.drift$mean,y.test)
SES <- accuracy(f.ses$mean,y.test)
HOLTLINEAR <- accuracy(f.holtlinear$mean,y.test)
HOLTWINTER_M <- accuracy(f.hw$mean,y.test)
AUTO_ETS <- accuracy(f.ets$mean,y.test)
AUTO_ARIMA <- accuracy(f.arima$mean,y.test)
TBATS <- accuracy(f.tbats$mean,y.test)
THETA <- accuracy(f.theta$mean,y.test)
f.all <-rbind(MEAN, NAIVE, SNAIVE, DRIFT, SES, HOLTLINEAR, HOLTWINTER_M,
AUTO_ETS, AUTO_ARIMA, TBATS, THETA)
rownames(f.all) <- c("MEAN","NAIVE","SNAIVE","DRIFT","SES","HOLT LINEAR",
"Multiplicative Holt-Winters","Auto ETS Model",
"Auto ARIMA Model", "TBATS", "Theta Method")
f.all
# Load the requires packages
library(hts)
library(fpp) # contains data sets
# Bottom level data
vn
# Load the requires packages
library(hts)
library(fpp) # contains data sets
# Bottom level data
vn
# Return the first time series
vn[,1]
# Convert the data into an hierarchy
y <- hts(vn, nodes=list(4, c(2,2,2,2)))
# Return the hierarchy
y
# Return the labels of the nodes at each level
y$labels
# Return the hierarchy
y
# Return the labels of the nodes at each level
y$labels
# Return how the nodes are organised
y$nodes
# Bottom-up approach
allf <- forecast.gts(y, h=4, method="bu", fmethod="ets")
# Summary of the output
allf
# All-levels forecasts
allts(allf)
# Bottom-level forecasts
allf$bts
# Plot all forecasts
plot(allf)
# Top-down approach (Average historical proportions)
# for proportion of historical averages, use "tdgsf"
# for forecast proportions, use "tdfp"
allf <- forecast.gts(y, h=4, method="tdgsa", fmethod="ets")
allf
plot(allf)
# Middle-out approach
allf <- forecast.gts(y, h=4, method="mo", fmethod="ets", level=1)
plot(allf)
# Optimal reconciliation approach
allf <- forecast.gts(y, h=4, method="comb", fmethod="ets")
plot(allf)
# Bottom level data
vn
# Return the first time series
vn[,1]
# Load the requires packages
library(hts)
library(fpp) # contains data sets
# Bottom level data
vn
# Return the first time series
vn[,1]
# Convert the data into an hierarchy
y <- hts(vn, nodes=list(4, c(2,2,2,2)))
# Return the hierarchy
y
# Return the labels of the nodes at each level
y$labels
# Return how the nodes are organised
y$nodes
# Training Data
data1 <- window(y, start = c(1998,1), end = c(2009,4))
data1
# Bottom level data
vn
# Return the first time series
vn[,1]
# Convert the data into an hierarchy
y <- hts(vn, nodes=list(4, c(2,2,2,2)))
# Return the hierarchy
y
# Return the labels of the nodes at each level
y$labels
# Return how the nodes are organised
y$nodes
# Training Data
data <- window(y, start = c(1998,1), end = c(2009,4))
# Test Data
test <- window(y, start=c(2010,1), end=c(2011,4))
# Bottom-up approach
bu_f <- forecast.gts(y, h=8, method="bu", fmethod="ets")
bu_f
# Bottom-up approach
bu_f <- forecast.gts(data, h=8, method="bu", fmethod="ets")
bu_f
test
bu_f
# Summary of the output
allf
# All-levels forecasts
allts(allf)
# All-levels forecasts
allts(bu_f)
aggref_bu<-aggts(bu_f, levels = 1)
aggref_bu # To get the forecast at defined level
aggref_bu<-aggts(bu_f, levels = 2) # To get the forecast at defined level
aggref_bu
aggref_bu<-aggts(bu_f, levels = 0) # To get the forecast at defined level
aggref_bu
# Bottom-level forecasts
allf$bts
# To get the forecast at defined level
aggref_bu<-aggts(bu_f, levels = 2)
aggref_bu
# Bottom-level forecasts
bu_f$bts
accuracy.gts(bu_f)
accuracy.gts(bu_f,test)
accuracy.gts(bu_f,test)
accuracy(bu_f, test, levels = 0)
accBU <- accuracy(bu_f, test, levels = 0)
write.csv(accBU,"MOA_BU.csv")
accBU <- accuracy(bu_f, test)
write.csv(accBU,"MOA_BU.csv")
smatrix(y)
# All-levels forecasts
allts(bu_f)
# To get the forecast at defined level
aggref_bu<-aggts(bu_f, levels = 2)
aggref_bu
# Plot all forecasts
plot(allf)
# Plot all forecasts
plot(bu_f)
# Plot all forecasts
plot(bu_f,test)
# Plot all forecasts
bu_f <- forecast.gts(y, h=8, method="bu", fmethod="ets")
plot(bu_f)
# Plot all forecasts
bu_f <- forecast.gts(y, h=8, method="bu", fmethod="ets")
bu_f
allts(bu_f)
plot(bu_f)
# Top-down approach (Average historical proportions)
# for proportion of historical averages, use "tdgsf"
# for forecast proportions, use "tdfp"
allf <- forecast.gts(y, h=4, method="tdgsa", fmethod="ets")
allf
plot(allf)
# Middle-out approach
allf <- forecast.gts(y, h=4, method="mo", fmethod="ets", level=1)
aggts(y)
# Bottom level data
vn
# Return the first time series
vn[,1]
# Convert the data into an hierarchy
y <- hts(vn, nodes=list(4, c(2,2,2,2)))
# Return the hierarchy
y
# Return the labels of the nodes at each level
y$labels
# Return how the nodes are organised
y$nodes
aggts(y)
# Bottom-up approach
bu_f <- forecast.gts(data, h=8, method="bu", fmethod="ets",weight="ols")
bu_f
# Bottom-up approach
bu_f <- forecast.gts(data, h=8, method="bu", fmethod="ets")
# Summary of the output
bu_f
# Optimal reconciliation approach
allf <- forecast.gts(y, h=4, method="comb", fmethod="ets")
allf
allf1 <- forecast.gts(y, h=4, method="comb", fmethod="ets",weights ="ols" )
allf1
allf2 <- forecast.gts(y, h=4, method="comb", fmethod="ets",weights ="wls" )
allf2
allf3 <- forecast.gts(y, h=4, method="comb", fmethod="ets",weights ="mint" )
allf3
# Load the necessary libraries
library(forecast)
library(MAPA)
library(tsutils)
# Load two time series, as before
ts1 <- ts(scan("ts1.txt"), start=c(2011,1), frequency=4)
ts2 <- ts(scan("ts2.txt"), start=c(2011,1), frequency=12)
plot(ts1)
plot(ts2)
# Load some test data; In order to evaluate the forecasts
ts1.test <- ts(scan("ts1out.txt"), start=c(2016,1), frequency=4)
ts2.test <- ts(scan("ts2out.txt"), start=c(2016,1), frequency=12)
# Model the 'ts2'
y <- ts2
y.test <- ts2.test
# Set forecast horizon
h <- length(y.test)
h
'Some Simple Forecasting Methods
********************************'
# 1. Mean Method
'***************'
# Mean value h times
f.mean <- meanf(y,h)
f.mean
f.mean$fitted # in-sample forecast value
plot(f.mean) # forecast with prediction interval
f.mean$mean
f.ses <- ses(y,h=h)
f.ses
f.holtlinear <- holt(y,h=h,damped=FALSE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear <- ts(f.holtlinear$mean,start=start(y.test),frequency=frequency(y.test))
ts.plot(y,y.test,f.holtlinear,col=c("blue","blue","red"))
f.holtlinear <- holt(y,h=h,damped=FALSE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- holt(y,h=h,damped=TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- holt(y,h=h,damped=FALSE, exponential = TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
plot(ts2)
f.holtlinear$method
f.holtlinear <- holt(y,h=h,damped=FALSE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$method
f.holtlinear <- holt(y,h=h,damped=FALSE,type="multiplicative") # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$method
f.holtlinear <- holt(y,h=h,damped=FALSE,type="multiplicative",exponential = TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$method
f.holtlinear <- holt(y,h=h,damped=FALSE,exponential = TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$method
# Load the necessary libraries
library(forecast)
library(MAPA)
library(tsutils)
ts2 <- ts(scan("ts2.txt"), start=c(2011,1), frequency=12)
plot(ts2)
ts2
ts2.test <- ts(scan("ts2out.txt"), start=c(2016,1), frequency=12)
ts2.test
# Model the 'ts2'
y <- ts2
y.test <- ts2.test
# Set forecast horizon
h <- length(y.test)
h
f.ses <- ses(y,h=h)
f.ses
f.ses$model
f.ses$mean
f.ses$fitted
f.ses <- ts(f.ses$mean,start=start(y.test),frequency=frequency(y.test))
ts.plot(y,y.test,f.ses,col=c("blue","blue","red"))
f.holtlinear <- holt(y,h=h,damped=FALSE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- holt(y,h=h,damped=FALSE,exponential = TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- holt(y,h=h,damped=TRUE,exponential = FALSE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- holt(y,h=h,damped=FALSE,exponential = TRUE) # damped=TRUE for damped trend
f.holtlinear
f.holtlinear$model
f.holtlinear <- ts(f.holtlinear$mean,start=start(y.test),frequency=frequency(y.test))
ts.plot(y,y.test,f.holtlinear,col=c("blue","blue","red"))
f.holtlinear <- holt(y,h=h,damped=FALSE,exponential = TRUE,type="multiplicative") # damped=TRUE for damped trend
f.holtlinear
# Load the required library
library(tsintermittent)
# Load the 'ts3' time series
y <- ts(scan("ts3.txt"), start=c(2011,1), frequency=12)
y
crost.decomp(y)
y <- ts(scan("ts3.txt"), start=c(2011,1), frequency=12)
y.test <- ts(scan("ts3out.txt"), start=c(2016,1), frequency=12)
# Set the forecat horizon to be equal to the test set
h <- length(y.test)
h
# Plot the series to get a general impression
plot(y)
# Decomposition of a time series
crost.decomp(y)
f.crost <- crost(y,h=h,outplot=TRUE)
f.crost
f.crost$weights # Values of Alphas
f.crost$model # Gives name of model applied
f.crost$components #
f.crost$frc.in
f.crost$frc.out # out-of-sample forecast (Demand/Interval)
f.sba <- crost(y,h=h,type="sba")
f.sba
f.sba$frc.out # out-of-sample forecast (Demand/Interval)
f.sbjc <- crost(y,h=h,type="sbj")
f.sbjc
f.sbjc$frc.out # out-of-sample forecast (Demand/Interval)
f.tsb <- tsb(y,h=h)
f.tsb
f.tsb$frc.out
f.imapa <- imapa(y,h=h)
f.imapa
f.imapa$frc.out
f.adida <- as.vector(imapa(y,h=h,minimumAL=h+1,maximumAL=h+1))
f.adida
f.adida$frc.out
# How to best evaluate forecasts of intermittent demand is an active research are.
# Here we will use ME and RMSE
f.all <- cbind(f.crost$frc.out,f.sba$frc.out,f.sbjc$frc.out,f.tsb$frc.out,
f.imapa$frc.out)
colnames(f.all) <- c("Croston","SBA","SBJ","TSB","MAPA")
k <- dim(f.all)[2]
k
y.all <- t(tcrossprod(rep(1,k),y.test))
y.all <- t(tcrossprod(rep(1,k),y.test))
y.all
f.all
E <- y.all - f.all
ME <- apply(E,2,mean)
RMSE <- sqrt(apply(E^2,2,mean))
res <- rbind(ME,RMSE)
print(res)
# Load the necessary libraries
library(forecast)
library(MAPA)
library(tsutils)
# Load two time series, as before
ts1 <- ts(scan("ts1.txt"), start=c(2011,1), frequency=4)
ts2 <- ts(scan("ts2.txt"), start=c(2011,1), frequency=12)
plot(ts1)
plot(ts2)
# Load some test data; In order to evaluate the forecasts
ts1.test <- ts(scan("ts1out.txt"), start=c(2016,1), frequency=4)
ts2.test <- ts(scan("ts2out.txt"), start=c(2016,1), frequency=12)
# Model the 'ts2'
y <- ts2
y.test <- ts2.test
# Set forecast horizon
h <- length(y.test)
h
'Some Simple Forecasting Methods
********************************'
fit.ar1 <- Arima(y,c(1,0,0))
fit.ar1
# Plot the resulting forecast and prediction intervals
plot(f.ar1)
f.ar1$fitted
f.ar1$level
f.ar1$mean
# Forecasting
f.ets <- forecast(fit.ets,h=h)
f.ets
# Plot the resulting forecast and prediction intervals
plot(f.ets)
# Add the true test values to the plot
# Forecasting
f.ets <- forecast(fit.ets,h=h)
f.ets
# Plot the resulting forecast and prediction intervals
plot(f.ets)
# Add the true test values to the plot
# Add the true test values to the plot
lines(y.test,col="red")
# Forecasting
f.ar1 <- forecast(fit.ar1,h=h)
f.ar1
# Plot the resulting forecast and prediction intervals
plot(f.ar1)
# Add the true test values to the plot
lines(y.test,col="red")
fit.ma1 <- Arima(y,c(0,0,1))
fit.ma1
# Forecasting
f.ma1 <- forecast(fit.ma1,h=h)
f.ma1
# Plot the resulting forecast and prediction intervals
plot(f.ma1)
# Add the true test values to the plot
lines(y.test,col="red")
fit.arima <- auto.arima(y)
fit.arima
# Forecasting
f.arima <- forecast(fit.arima, h=h)
f.arima
# Check the following two commands--- needs correction
plot(f.arima)
lines(y.test,col="red")
fit.ets <- ets(y)
fit.ets
# Load the required library
library(tsintermittent)
# Load the 'ts3' time series
y <- ts(scan("ts3.txt"), start=c(2011,1), frequency=12)
y.test <- ts(scan("ts3out.txt"), start=c(2016,1), frequency=12)
# Set the forecat horizon to be equal to the test set
h <- length(y.test)
h
# Data points
y
# Plot the series to get a general impression
plot(y)
crost.decomp(y)
f.crost <- crost(y,h=h,outplot=TRUE)
f.crost
f.crost$weights # Values of Alphas
f.crost$model # Gives name of model applied
f.crost$components # non-zero demand & inter-demand interval components
f.crost$frc.in # In-sample forcast (fitted) values (Demand/Interval)
f.crost$frc.out # out-of-sample forecast (Demand/Interval)
f.sba <- crost(y,h=h,type="sba")
f.sba
f.sba$frc.out # out-of-sample forecast (Demand/Interval)
